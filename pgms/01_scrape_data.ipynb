{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Program:** 01_scrape_data.ipynb <br>\n",
    "**Created by:** Chris Chan<br>\n",
    "**Date:** Jan 14, 2021<br>\n",
    "**Purpose:** Using selenium, scrape jazz vinyl data from discogs.com<br>\n",
    "**Key Features:** Price, media condition, sleeve condition, release date, artist, album, record label, haves, wants, ratings, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Ideas:\n",
    "- Predict (collector) vinyl price\n",
    "- https://blog.discogs.com/en/discogs-top-100-most-expensive-records/\n",
    "- limits: only 100 data points\n",
    "- can we obtain # copies/presses\n",
    "- The goal isn't to analyze why recs have gone up in general, but if collector, what are some attributes that may predict the price. OR we can ask what are some attributes that predict the RATINGS of expensive recs\n",
    "\n",
    "**UPDATED** \n",
    "**DISCOGS**\n",
    "- most expensive lists: https://www.discogs.com/lists?list=expensive+items&page=2\n",
    "- use this to obtain all years (2010-2019)\n",
    "- example of month (jan2010): https://www.discogs.com/lists/Most-expensive-items-sold-in-Discogs-Marketplace-for-October-2010/140095\n",
    "- example of album within month (jan2010): https://www.discogs.com/La-Monte-Young-Drift-Study-43740-50950-PM-5-VIII-68-NYC/release/1512276\n",
    "- example of 100 expensive from archives: http://web.archive.org/web/20180502225137/https://blog.discogs.com/en/discogs-top-100-most-expensive-records/\n",
    "- graph of 10 years: https://blog.discogs.com/en/discogs-top-100-most-expensive-records/\n",
    "\n",
    "**MISC MUSIC**\n",
    "- vinylfactory: https://thevinylfactory.com/features/online-tools-for-record-collectors/\n",
    "- links to spotify: http://www.disconest.com/\n",
    "- discogs misc: https://web.archive.org/web/20210106081812/https://blog.discogs.com/en/\n",
    "- discogs misc: https://blog.discogs.com/en/vinyl-record-price-guide/\n",
    "- data: https://www.discogs.com/developers#page:user-collection\n",
    "- data: https://data.discogs.com/?prefix=data/2020/\n",
    "- pitchfork: https://pitchfork.com/reviews/best/reissues/?page=1\n",
    "- spotify github: https://github.com/nsgrantham/pitchfork-reviews\n",
    "- spotify kaggle: https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks\n",
    "- spotify medium: https://towardsdatascience.com/step-by-step-to-visualize-music-genres-with-spotify-api-ce6c273fb827\n",
    "- discogs (full code): http://www.diva-portal.org/smash/get/diva2:1443317/FULLTEXT01.pdf\n",
    "\n",
    "**NEW LIST - ALL ITEMS. Need to pare down to something specific**\n",
    "**to consider:**\n",
    "- vintage vinyl years?\n",
    "- jazz only?\n",
    "- certain format?\n",
    "- create ranking of how many times an arist shows up in list\n",
    "- differential in haves and wants?\n",
    "- price history?\n",
    "\n",
    "- dicogs: lists: https://www.discogs.com/user/discogs/lists?header=1\n",
    "- https://medium.com/@kdavis7190/vinyl-resale-price-prediction-6cb0adaedcb9\n",
    "- https://github.com/kdavis01/projects/blob/master/vinyl_resale_regression/Data_Gathering.ipynb\n",
    "\n",
    "**For Write up:**\n",
    "- https://dgmono.com/2014/01/08/perspective-collecting-vintage-jazz-vinyl-a-labor-of-love/\n",
    "- miles davis - kind of blue will change your life - reasons for grabbing more exp recs ($25 for reissue these days)\n",
    "    - or you can just find avg price of jazz records in general\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the program I ulimately used to scrape Discogs data. My previous attempts using beautifulsoup kept giving me limitation issues. Therefore I went the Selenium route. Some of this code was borrowed from a previous Metis project that was found on github**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1664.3 Safari/537.36\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## allows us to use reg expressions to search fields\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "# user agent\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "options = Options()\n",
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "print(userAgent)\n",
    "options.add_argument(f'user-agent={userAgent}')\n",
    "\n",
    "#driver = webdriver.Chrome(chrome_options=options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Selenium to scrape album contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-68-b61d773ed8c1>:1: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chromedriver,chrome_options=options)\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(chromedriver,chrome_options=options)\n",
    "\n",
    "# update the page here to start where left off. Page is essentially the count as well\n",
    "pagestart=21\n",
    "pageend=34\n",
    "\n",
    "#_url = \"https://www.discogs.com/sell/list?sort=price%2Cdesc&limit=100&year1=1900&year2=1970&format=Vinyl&price=over40&genre=Jazz&currency=USD&style=Hard+Bop&page=\"\n",
    "# not just bebop\n",
    "_url = \"https://www.discogs.com/sell/list?sort=price%2Cdesc&limit=100&year1=1900&year2=1970&format=Vinyl&genre=Jazz&currency=USD&style=Hard+Bop&price=20to40&page=\"\n",
    "url= _url + str(pagestart) + \"#more%3Dyear\" \n",
    "\n",
    "# starting url\n",
    "#driver.get(\"https://www.discogs.com/sell/list?sort=price%2Cdesc&limit=100&year1=1900&year2=1970&format=Vinyl&price=over40&genre=Jazz&currency=USD&style=Hard+Bop&page=3#more%3Dyear\")\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "with open('recorddata.csv', 'w',newline='') as csvfile:\n",
    "    file = csv.writer(csvfile)\n",
    "    # make headers\n",
    "    file.writerow(['Artist_Album', 'Label', 'Country', 'Format', 'Notes', 'Genre', 'Release_Date', 'Style', 'Rate_Haves_Wants', 'Media_Condition',\n",
    "                     'Sleeve_Condition', 'Seller_Rating', 'Recorded_at', 'Pressed_by', 'Price'])\n",
    "    count = pagestart #3\n",
    "    \n",
    "    while count < pageend: # 7:\n",
    "        \n",
    "        # find all links on album marketplace page and store in list\n",
    "\n",
    "        result_elements = '//a[contains(@href, \"/sell/item/\")]'\n",
    "\n",
    "        albums = []\n",
    "\n",
    "        albumdriver = driver.find_elements_by_xpath(result_elements)\n",
    "\n",
    "        for url in albumdriver:\n",
    "            albums.extend([url.get_attribute('href')])\n",
    "        \n",
    "        # get rid of duplicates\n",
    "\n",
    "        albumsclean = [album.split('?', 1)[0] for album in albums]\n",
    "        albumurls = set(albumsclean)\n",
    "\n",
    "        # scrape info from album page\n",
    "\n",
    "        for album in albumurls:\n",
    "            \n",
    "            driver.get(album)\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            try:\n",
    "                artist_album = driver.find_element_by_xpath(\"//h1[contains(@id, 'profile_title')]\").text.strip()\n",
    "            except:\n",
    "                artist_album = np.nan\n",
    "        \n",
    "            ## cc: label\n",
    "            try:\n",
    "                rlabel = driver.find_element_by_xpath(\"//div[contains(text(), 'Label:')]/following-sibling::div\").text.strip()\n",
    "            except:\n",
    "                rlabel = np.nan\n",
    "                \n",
    "            ## cc: country\n",
    "            try:\n",
    "                country = driver.find_element_by_xpath(\"//div[contains(text(), 'Country:')]/following-sibling::div\").text.strip()\n",
    "            except:\n",
    "                country = np.nan    \n",
    "            \n",
    "            ## cc: format\n",
    "            try:\n",
    "                rformat = driver.find_element_by_xpath(\"//div[contains(text(), 'Format:')]/following-sibling::div\").text.strip()\n",
    "            except:\n",
    "                rformat = np.nan    \n",
    "                \n",
    "            ## cc: notes\n",
    "            try:\n",
    "                notes = driver.find_element_by_xpath(\"//h3[contains(text(), 'Notes')]/following-sibling::div\").text.strip()\n",
    "            except:\n",
    "                notes = np.nan    \n",
    "                        \n",
    "            \n",
    "            try:\n",
    "                genre = driver.find_element_by_xpath(\"//div[contains(text(), 'Genre:')]/following-sibling::div\").text.strip()\n",
    "            except:\n",
    "                genre = np.nan\n",
    "\n",
    "            try:\n",
    "                release_date = driver.find_element_by_xpath(\"//div[contains(text(), 'Released:')]/following-sibling::div\").text.strip()\n",
    "            except:\n",
    "                release_date = np.nan\n",
    "\n",
    "            try:\n",
    "                style = driver.find_element_by_xpath(\"//div[contains(text(), 'Style:')]/following-sibling::div\").text.strip()\n",
    "            except:\n",
    "                style = np.nan\n",
    "\n",
    "            try:\n",
    "                rate_haves_wants = driver.find_element_by_xpath(\"//a[contains(@class, 'button-blue')]/following-sibling::div\").text.strip()\n",
    "            except:\n",
    "                rate_haves_wants = np.nan\n",
    "\n",
    "            try:\n",
    "                m_condition = driver.find_element_by_xpath(\"//strong[contains(text(), 'Media:')]/following-sibling::span\").text.strip()\n",
    "            except:\n",
    "                m_condition = np.nan\n",
    "    \n",
    "            try:\n",
    "                sleeve = driver.find_element_by_xpath(\"//strong[contains(text(), 'Sleeve:')]\")\n",
    "                s_condition = sleeve.find_element_by_xpath('..').text.strip()\n",
    "            except:\n",
    "                s_condition = np.nan\n",
    "\n",
    "            try:\n",
    "                seller_rating = driver.find_element_by_xpath(\"//span[@class='star_rating']/following-sibling::strong\").text.strip()\n",
    "            except:\n",
    "                seller_rating = np.nan\n",
    "\n",
    "            # recorded at        \n",
    "            try:\n",
    "                recorded_at = driver.find_element_by_xpath(\"//span[contains(text(),'Recorded At')]/following-sibling::a\").text.strip()\n",
    "            except:\n",
    "                recorded_at = np.nan    \n",
    "                \n",
    "            # pressed at\n",
    "            try:\n",
    "                pressed_by = driver.find_element_by_xpath(\"//span[contains(text(),'Pressed By')]/following-sibling::a\").text.strip()\n",
    "            except:\n",
    "                pressed_by = np.nan    \n",
    "    \n",
    "\n",
    "            try:\n",
    "                price = soup.find(class_='price').text.strip()\n",
    "            except:\n",
    "                price = np.nan\n",
    "\n",
    "            observation = [artist_album, rlabel, country, rformat, notes, genre, release_date, style, rate_haves_wants, m_condition, \n",
    "                           s_condition, seller_rating, recorded_at, pressed_by, price]\n",
    "\n",
    "            file.writerow(observation)\n",
    "\n",
    "            time.sleep(.5+2*random.random())\n",
    "            \n",
    "        # go to next page in the marketplace\n",
    "        \n",
    "        #nextpage = \"https://www.discogs.com/sell/list?sort=listed%2Casc&currency=USD&limit=25&page=\" + str(count+1) + \"&format=Vinyl\"\n",
    "        #nextpage = \"https://www.discogs.com/sell/list?sort=price%2Cdesc&limit=100&year1=1900&year2=1970&format=Vinyl&price=over40&genre=Jazz&currency=USD&style=Hard+Bop&page=\" + str(count+1) + \"#more%3Dyear\"\n",
    "        nextpage = \"https://www.discogs.com/sell/list?sort=price%2Cdesc&limit=100&year1=1900&year2=1970&format=Vinyl&genre=Jazz&currency=USD&style=Hard+Bop&price=20to40&page=\" + str(count+1)\n",
    "        driver.get(nextpage)\n",
    "        \n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
